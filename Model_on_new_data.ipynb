{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_on_new_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "qiUe8lk8qVF-"
      ],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "X6mAiK35DqMU",
        "outputId": "4a079dbe-b88b-4550-de0b-a20f7c9cfd3c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "#files to open: utils, GRU_sequence_weights.h5, folder Search/search, output, train.csv\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-885676f1-48ec-4e49-aed1-16f1b78d9a93\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-885676f1-48ec-4e49-aed1-16f1b78d9a93\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving search to search\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "95NBzOnOqn-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "\n",
        "#from utils import model_LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0Xtsth6E7Zr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deltas_in_search(file_name = 'search'):\n",
        "    file_search = open(file_name, 'r')\n",
        "\n",
        "    count = 0\n",
        "    for line in file_search:\n",
        "        count +=1\n",
        "        if count == 5:\n",
        "            break\n",
        "        continue\n",
        "\n",
        "    deltas = {}\n",
        "\n",
        "    for line in file_search:\n",
        "        if line.find('Searching') != -1:\n",
        "            J0 = int(line.split()[1])\n",
        "            deltas[J0] = []\n",
        "            E0 = float(line.split()[-1])\n",
        "            continue\n",
        "\n",
        "        if line.find('No') != -1 or \\\n",
        "           len(line.split()) == 0 or \\\n",
        "           int(line.split()[0]) != int(J0) - 1 or\\\n",
        "           len(line.split()) == 6:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            E = float(line.split()[-1])\n",
        "            delta = round(E - E0, 3)\n",
        "            deltas[J0].append(delta)\n",
        "        except ValueError:\n",
        "            break\n",
        "            \n",
        "    return deltas\n",
        "\n",
        "def search_for_3tr(file_name = 'search', numb_tr=2):\n",
        "    file_search = open(file_name, 'r')\n",
        "\n",
        "    add = ''\n",
        "    count = 0\n",
        "    for line in file_search:\n",
        "        add += line\n",
        "        count +=1\n",
        "        if count == 5:\n",
        "            break\n",
        "        continue\n",
        "\n",
        "    deltas = {}\n",
        "    lines = file_search.readlines()\n",
        "    file_search.close()\n",
        "    \n",
        "    file_search = open(file_name, 'w')\n",
        "    file_search.write(add)\n",
        "    for i in range(len(lines)):\n",
        "        \n",
        "        line = lines[i]\n",
        "        if line.find('Searching') != -1:\n",
        "            file_search.write('\\n' + line)\n",
        "            J0 = int(line.split()[1])\n",
        "            #eltas[J0] = []\n",
        "            #E0 = float(line.split()[-1])\n",
        "            continue\n",
        "\n",
        "        if line.find('No') != -1 or \\\n",
        "           len(line.split()) == 0 or \\\n",
        "           int(line.split()[0]) != int(J0) - 1:\n",
        "            continue\n",
        "\n",
        "        if len(line.split()) == 12 and len(lines[i+1].split()) == 6:\n",
        "                #E = float(line.split()[-1])\n",
        "                #delta = str(round(E - E0, 3))\n",
        "                file_search.write(line)\n",
        "                #file_search.write(lines[i+1])\n",
        "        else:continue\n",
        "    file_search.close()\n",
        "    return None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qiUe8lk8qVF-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Writing out predictions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KjdJPCVvfm4c",
        "outputId": "01d9d4ed-7509-47cc-d9bd-a78b6d4e9314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "random.seed(227)\n",
        "\n",
        "file_csv = open('output_predictions', 'w', newline='')\n",
        "\n",
        "filewriter = csv.writer(file_csv, delimiter=',',\n",
        "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "filewriter.writerow([1,2,3,4,5,6])\n",
        "for i in range(int(len(data)/2), len(data)):\n",
        "    filewriter.writerow(data[i])\n",
        "\n",
        "#files.download('train.csv')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-49dfd05ad09f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                             quotechar='|', quoting=csv.QUOTE_MINIMAL)\n\u001b[1;32m      9\u001b[0m \u001b[0mfilewriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfilewriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cZUpGGAkgMsz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_csv.close()\n",
        "files.download('test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FT9hA_ADE7Zb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN model"
      ]
    },
    {
      "metadata": {
        "id": "mMWUKhBusHuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61b89460-c016-40b5-c9f0-557497de02c2"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Input, GRU, LSTM, TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def model_LSTM2(hidden_size, Tx):  \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(hidden_size, return_sequences=False, input_shape=(Tx,1)))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "  \n",
        "    return model\n",
        "\n",
        "def model_LSTM_many_to_many(hidden_size):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(hidden_size, return_sequences=True,input_shape=(Tx,1)))\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "    \n",
        "  \n",
        "  return model\n",
        "\n",
        "def model_LSTM_many_to_many_TD(hidden_size):\n",
        "  X = Input(shape=(6, 1))\n",
        "  h = LSTM(hidden_size, return_sequences=True)(X)\n",
        "  output = TimeDistributed(Dense(units=2, activation='softmax'))(h)        \n",
        "    \n",
        "  model = Model(inputs=X, outputs=output)\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "A3A-jKMgE7ZR",
        "colab_type": "code",
        "outputId": "2c11ff8e-a458-4462-ae30-41a2cef2bddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "Tx, Ty =  6, 1\n",
        "\n",
        "model = model_LSTM_many_to_many_TD(16)\n",
        "print(model.summary())\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 6, 1)              0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 6, 16)             1152      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 6, 2)              34        \n",
            "=================================================================\n",
            "Total params: 1,186\n",
            "Trainable params: 1,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MmplzWjnsMs_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#LSTM_model.load_weights('sources/LSTM_sequence_weights.h5')\n",
        "model.load_weights('LSTM_sequence_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "luMikCUd2PNX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# To get search file use Prepare_test notebook"
      ]
    },
    {
      "metadata": {
        "id": "fXXbFAWWE7Zt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Calculate deltas on base on ready search file"
      ]
    },
    {
      "metadata": {
        "id": "zAeTMm0IE7Zw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "search_for_3tr()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "csuIysSxE7Zu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seria_name, quan_num = 'J1J-1', [2, 1, 1]\n",
        "peak_file = 'expfile_st'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SZ26Rb9zveWZ",
        "colab_type": "code",
        "outputId": "668ef08d-a9d4-4876-b4fc-ec0be5eeffc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "deltas = deltas_in_search()\n",
        "k_ini = list(deltas.keys())[0]\n",
        "\n",
        "deltas = {k:v for k,v in deltas.items() if k < Tx+k_ini and k>1}\n",
        "for k,v in deltas.items():\n",
        "  print(k,v)\n",
        "\n",
        "for k,v in deltas.items():\n",
        "  print(k,len(v))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 [-0.489, -0.482, -0.476, -0.468, -0.459, -0.45, -0.438, -0.424, -0.418, -0.414, -0.408, -0.401, -0.386, -0.358, -0.353, -0.347, -0.343, -0.281, -0.277, -0.272, -0.257, -0.253, -0.231, -0.222, -0.216, -0.209, -0.186, -0.169, -0.162, -0.154, -0.146, -0.136, -0.128, -0.123, -0.118, -0.105, -0.1, -0.075, -0.067, -0.051, -0.043, -0.037, -0.032, -0.022, -0.016, 0.013, 0.018, 0.023, 0.034, 0.054, 0.067, 0.076, 0.081, 0.087, 0.106, 0.121, 0.131, 0.146, 0.151, 0.168, 0.176, 0.182, 0.192, 0.207, 0.211, 0.217, 0.243, 0.247, 0.252, 0.259, 0.271, 0.307, 0.313, 0.318, 0.329, 0.354, 0.369, 0.374, 0.384, 0.405, 0.414, 0.434, 0.454, 0.459, 0.465, 0.478, 0.486, 0.49, 0.496, 0.502, -0.438, -0.414, -0.408, -0.386, -0.353, -0.277, -0.146, -0.136, -0.067, -0.051, -0.032, 0.013, 0.076, 0.106, 0.176, 0.182, 0.252, 0.259, 0.496, 0.502]\n",
            "3 [-0.498, -0.492, -0.488, -0.482, -0.47, -0.454, -0.449, -0.439, -0.436, -0.421, -0.412, -0.397, -0.377, -0.35, -0.341, -0.336, -0.324, -0.32, -0.313, -0.308, -0.302, -0.283, -0.273, -0.262, -0.248, -0.238, -0.233, -0.228, -0.218, -0.211, -0.195, -0.166, -0.155, -0.145, -0.119, -0.1, -0.095, -0.051, -0.036, 0.003, 0.008, 0.014, 0.028, 0.047, 0.05, 0.078, 0.084, 0.098, 0.133, 0.144, 0.158, 0.163, 0.178, 0.192, 0.196, 0.201, 0.209, 0.217, 0.24, 0.249, 0.253, 0.263, 0.275, 0.297, 0.311, 0.341, 0.376, 0.391, 0.396, 0.401, 0.407, 0.411, 0.45, 0.465, 0.486, 0.493, -0.273, -0.248, -0.233, -0.228, 0.008, 0.201, 0.341, 0.376, 0.391, 0.396]\n",
            "4 [-0.503, -0.499, -0.49, -0.485, -0.479, -0.472, -0.461, -0.455, -0.434, -0.414, -0.409, -0.369, -0.36, -0.355, -0.345, -0.322, -0.308, -0.295, -0.289, -0.281, -0.272, -0.265, -0.254, -0.251, -0.226, -0.217, -0.21, -0.196, -0.182, -0.176, -0.169, -0.165, -0.159, -0.155, -0.116, -0.111, -0.084, -0.077, -0.072, -0.066, -0.055, -0.049, -0.043, -0.026, -0.015, -0.005, 0.0, 0.011, 0.016, 0.029, 0.041, 0.052, 0.07, 0.079, 0.085, 0.09, 0.123, 0.136, 0.143, 0.159, 0.178, 0.211, 0.218, 0.232, 0.237, 0.249, 0.255, 0.268, 0.276, 0.281, 0.29, 0.295, 0.305, 0.315, 0.334, 0.355, 0.37, 0.389, 0.395, 0.4, 0.46, 0.468, 0.476, 0.488, 0.499, -0.485, -0.461, -0.369, -0.265, -0.196, -0.176, -0.169, -0.055, 0.07, 0.143, 0.211, 0.315, 0.395, 0.468]\n",
            "5 [-0.481, -0.476, -0.472, -0.467, -0.448, -0.44, -0.423, -0.416, -0.401, -0.337, -0.295, -0.29, -0.26, -0.253, -0.239, -0.205, -0.188, -0.166, -0.141, -0.135, -0.127, -0.108, -0.098, -0.093, -0.088, -0.083, -0.077, -0.048, -0.041, -0.038, -0.032, -0.028, -0.007, 0.012, 0.023, 0.048, 0.059, 0.066, 0.074, 0.08, 0.086, 0.091, 0.116, 0.143, 0.149, 0.162, 0.205, 0.214, 0.218, 0.228, 0.243, 0.253, 0.264, 0.268, 0.277, 0.283, 0.294, 0.305, 0.327, 0.348, 0.353, 0.359, 0.384, 0.416, 0.422, 0.429, 0.433, 0.439, 0.448, 0.457, 0.491, -0.253, -0.098, -0.088, -0.083, -0.048, -0.007, 0.059, 0.086, 0.353, 0.384]\n",
            "6 [-0.495, -0.484, -0.477, -0.466, -0.456, -0.444, -0.427, -0.405, -0.388, -0.382, -0.376, -0.367, -0.362, -0.351, -0.341, -0.336, -0.325, -0.319, -0.312, -0.3, -0.288, -0.274, -0.249, -0.244, -0.224, -0.21, -0.193, -0.167, -0.164, -0.159, -0.141, -0.133, -0.127, -0.121, -0.115, -0.099, -0.095, -0.089, -0.084, -0.079, -0.065, -0.06, -0.051, -0.045, -0.034, -0.028, -0.019, -0.005, 0.009, 0.032, 0.037, 0.042, 0.052, 0.058, 0.065, 0.07, 0.079, 0.093, 0.128, 0.159, 0.164, 0.168, 0.183, 0.209, 0.246, 0.252, 0.256, 0.26, 0.321, 0.335, 0.341, 0.379, 0.391, 0.398, 0.403, 0.408, 0.413, 0.464, 0.472, 0.477, 0.493, 0.499, -0.495, -0.325, -0.319, -0.312, -0.244, -0.167, -0.099, -0.028, -0.005, 0.009, 0.042, 0.052, 0.093, 0.159, 0.341]\n",
            "7 [-0.502, -0.497, -0.478, -0.468, -0.449, -0.415, -0.376, -0.361, -0.357, -0.352, -0.333, -0.324, -0.314, -0.299, -0.277, -0.263, -0.258, -0.253, -0.247, -0.245, -0.239, -0.229, -0.225, -0.22, -0.214, -0.205, -0.199, -0.184, -0.165, -0.16, -0.142, -0.132, -0.124, -0.109, -0.099, -0.062, -0.032, -0.027, -0.022, -0.015, 0.025, 0.03, 0.035, 0.04, 0.046, 0.063, 0.093, 0.104, 0.111, 0.116, 0.125, 0.135, 0.159, 0.187, 0.193, 0.214, 0.242, 0.261, 0.266, 0.271, 0.275, 0.279, 0.284, 0.303, 0.307, 0.314, 0.326, 0.35, 0.372, 0.395, 0.41, 0.424, 0.435, 0.441, 0.469, 0.474, 0.479, -0.502, -0.415, -0.357, -0.229, -0.199, -0.165, 0.025, 0.116, 0.159, 0.242, 0.279, 0.284, 0.326, 0.435, 0.441, 0.469]\n",
            "2 110\n",
            "3 86\n",
            "4 99\n",
            "5 81\n",
            "6 97\n",
            "7 93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GXcADACPE7Z0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Make sequences and PREDICTION "
      ]
    },
    {
      "metadata": {
        "id": "51oWV4h8E7Z1",
        "colab_type": "code",
        "outputId": "83323326-2ea2-426d-db06-e99228afe503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "numb_seq = 1\n",
        "for k,v in deltas.items():\n",
        "    #if k >4: continue\n",
        "    numb_seq *= len(deltas[k])\n",
        "print(numb_seq/1000000,  'millions')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "684330.71454 millions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C696MAtqE7aC",
        "colab_type": "code",
        "outputId": "f028d749-fcc8-4f37-e572-7d923d77f1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "data_train = pd.read_csv('train.csv')\n",
        "X = data_train.drop(['Y'], axis='columns').values\n",
        "\n",
        "ss = StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndata_train = pd.read_csv('train.csv')\\nX = data_train.drop(['Y'], axis='columns').values\\n\\nss = StandardScaler()\\nX = ss.fit_transform(X)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "WGWMTHxn5BG9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def scale_substraction_mean_for_1sample(X):\n",
        "  for i in range(X.shape[0]):\n",
        "    line = X[i]\n",
        "    mean = np.mean(line)\n",
        "    X[i] = line - mean \n",
        "    \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3Q1JwUHE7aF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keys = list(deltas.keys())\n",
        "ini_key = keys[0]\n",
        "sequence = []\n",
        "counter = 0\n",
        "data_out = []\n",
        "\n",
        "def sequence_predict(k, seq_ini, data_out, counter=counter):\n",
        "    for v in deltas[k]:\n",
        "        #print(k,v, seq_ini)\n",
        "        sequence = seq_ini.copy()\n",
        "        sequence.append(v)\n",
        "        #print(sequence)\n",
        "        \n",
        "        if counter % 100000 == 0 and len(sequence) == 6:\n",
        "                print('!',counter/100000)\n",
        "                print(len(data_out))\n",
        "\n",
        "        #if counter % 100000 == 0 and len(sequence) == 6:\n",
        "                #print(sequence)\n",
        "        if len(sequence) == len(deltas.items()):\n",
        "            counter += 1\n",
        "            sequence_np = np.array([sequence])\n",
        "            sequence_np = scale_substraction_mean_for_1sample(sequence_np)\n",
        "            sequence_np = np.expand_dims(sequence_np, axis=2)\n",
        "            \n",
        "            prediction = model.predict(sequence_np)\n",
        "            prediction = np.argmax(prediction, axis = -1)\n",
        "            #print(prediction)\n",
        "            if 0 in prediction:\n",
        "              index_0 = prediction.tolist()[0].index(0)\n",
        "              key = keys[index_0]\n",
        "              \n",
        "              return key, counter, data_out\n",
        "            \n",
        "            else:\n",
        "              print(prediction, sequence)\n",
        "              k_back = 7#print(prediction,sequence,sequence_np)\n",
        "            a=input()\n",
        "            \n",
        "            '''if prediction[:,-1,:] > 0.5:\n",
        "                to_out = []\n",
        "                to_out.append(prediction.tolist())\n",
        "                to_out.append(sequence)\n",
        "                to_out.append(np.squeeze(sequence_np, axis=2).tolist()[0])\n",
        "                data_out.append(to_out)\n",
        "                print(to_out)\n",
        "                \n",
        "                print('')\n",
        "                for el in data_out:\n",
        "                  print(el)\n",
        "                a=input()\n",
        "              \n",
        "               '''\n",
        "        else:\n",
        "            k_back, counter, data_out = sequence_predict(k+1, sequence, data_out, counter=counter)\n",
        "        \n",
        "        #print('back', k, seq_ini)\n",
        "        if k > k_back:\n",
        "          return k_back, counter, data_out\n",
        "        if k in list(deltas.keys())[:2]:\n",
        "          print(k, 'Finished: ', sequence)\n",
        "        #print(k ,k_back)\n",
        "    return k, counter, data_out\n",
        "        \n",
        "k_0, counter, data_out = sequence_predict(ini_key,sequence, data_out, counter=counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qS1IyOdGsisT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keys = list(deltas.keys())\n",
        "ini_key = keys[0]\n",
        "sequence = []\n",
        "counter = 0\n",
        "data_out = []\n",
        "\n",
        "def sequence_predict_many_to_many(k, seq_ini, data_out, counter=counter):\n",
        "    for v in deltas[k]:\n",
        "        sequence = seq_ini.copy()\n",
        "        sequence.append(v)\n",
        "        \n",
        "        if counter % 100000 == 0 and len(sequence) == 6:\n",
        "                print('!',counter/100000)\n",
        "                print(len(data_out))\n",
        "\n",
        "        if len(sequence) == len(deltas.items()):\n",
        "            counter += 1\n",
        "            sequence_np = np.array([sequence])\n",
        "            sequence_np = scale_substraction_mean_for_1sample(sequence_np)\n",
        "            sequence_np = np.expand_dims(sequence_np, axis=2)\n",
        "            \n",
        "            prediction = model.predict(sequence_np)\n",
        "            prediction = np.argmax(prediction, axis=-1)\n",
        "            \n",
        "            print(prediction,sequence,sequence_np)\n",
        "            \n",
        "            if prediction.tolist()[0][-1] == 0:\n",
        "              index_0 = prediction.tolist()[0].index(0)\n",
        "              \n",
        "             \n",
        "              \n",
        "            \n",
        "            a=input()\n",
        "            \n",
        "            if prediction[:,-1,:] > 0.5:\n",
        "                to_out = []\n",
        "                to_out.append(prediction.tolist())\n",
        "                to_out.append(sequence)\n",
        "                to_out.append(np.squeeze(sequence_np, axis=2).tolist()[0])\n",
        "                data_out.append(to_out)\n",
        "                print(to_out)\n",
        "                '''\n",
        "                print('')\n",
        "                for el in data_out:\n",
        "                  print(el)\n",
        "                a=input()\n",
        "                '''\n",
        "        else:\n",
        "            counter, data_out = sequence_predict_many_to_many(k+1, sequence, data_out, counter=counter)\n",
        "        \n",
        "        if k in list(deltas.keys())[:3]:\n",
        "          print(k, 'Finished: ', sequence)\n",
        "       \n",
        "    return counter, data_out\n",
        "        \n",
        "counter, data_out = sequence_predict_many_to_many(ini_key,sequence, data_out, counter=counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UlmC_5NW-NLe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for line in data_out:\n",
        "  print(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UqPG9xNG9U8s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_out = open('out.txt', 'w')\n",
        "\n",
        "for line in data_out:\n",
        "  el1 = ', '.join(list(map(str,line[1])))\n",
        "  el2 = ', '.join(list(map(str,line[2]))) \n",
        "  el0 = str(line[0])\n",
        "  file_out.write(' ,'.join([el0, el1, el2]) + '\\n')\n",
        "  \n",
        "file_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bDkC9fhq983M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('out.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JBDyRDuT-nBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}