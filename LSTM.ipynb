{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "GDtJzrsw_P9P",
        "colab_type": "code",
        "outputId": "46ab1cd7-d216-4af9-f609-bda688aa7f2d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "#files to open: train and test data,\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e2e3ae7-603d-4300-ae23-a8cfd3423a1f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7e2e3ae7-603d-4300-ae23-a8cfd3423a1f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train_y1_v8.csv to train_y1_v8.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "21d8nmrzFEED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports and functions"
      ]
    },
    {
      "metadata": {
        "id": "XiZyQ_BR_No6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import recall_score, precision_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbPTiaHb_NpC",
        "colab_type": "code",
        "outputId": "0ba4dd67-0631-4211-cb98-fe624de22c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bfeW1EwG_NpF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_loss(epochs, loss, val_loss):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(np.arange(epochs), loss, label='loss')\n",
        "    plt.plot(np.arange(epochs), val_loss, label='val_loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "def acc_graph(epochs, train_acc, val_acc):\n",
        "    x_axis = np.linspace(1, epochs, num=epochs)\n",
        "    \n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(x_axis, train_acc, color='g', lw=3, alpha=0.7, label='Train Accuracy')\n",
        "    plt.plot(x_axis, val_acc, color='orange', lw=3, alpha=0.7, label='Val Accuracy')\n",
        "    plt.title('Accuracy graph')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_hj_szh_NpH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculation_classes(y, y_test = None):\n",
        "    print ('\\t\\tTRAIN DATA\\tTEST DATA')\n",
        "    print ('Negative\\t', np.sum(y==0),'  ',\n",
        "           round(100*np.sum(y==0)/y.shape[0],2),'%',\n",
        "           '\\t',np.sum(y_test==0),'  ',\n",
        "           round(100*np.sum(y_test==0)/y_test.shape[0],2),'%'\n",
        "           '\\nPositive\\t ', np.sum(y==1),' ',\n",
        "           round(100*np.sum(y==1)/y.shape[0],2),'%'\n",
        "           '\\t',np.sum(y_test==1),' ',\n",
        "           round(100*np.sum(y_test==1)/y_test.shape[0],2),'%'\n",
        "      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j4ZUJDQE_NpK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from utils import model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-zc8IV-QyDA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def scale_0_1_for_samples(X):\n",
        "  mm = MinMaxScaler()\n",
        "\n",
        "  for i in range(X.shape[0]):\n",
        "    line = X[i]\n",
        "    #print(line)\n",
        "  \n",
        "    line = line.reshape(-1, 1)\n",
        "    X[i] = mm.fit_transform(line).reshape(1,-1)\n",
        "  return X\n",
        " \n",
        "def scale_standard_for_1sample(X):\n",
        "  ss = StandardScaler()\n",
        "\n",
        "  for i in range(X.shape[0]):\n",
        "    line = X[i]\n",
        "    X[i] = ss.fit_transform(line.reshape(-1,1)).reshape(1,-1)\n",
        "  return X\n",
        "\n",
        "def scale_substraction_mean_for_1sample(X):\n",
        "  for i in range(X.shape[0]):\n",
        "    line = X[i]\n",
        "    #print(line)\n",
        "    mean = np.mean(line)\n",
        "    #print(mean)\n",
        "    X[i] = line - mean\n",
        "    #print(X[i])\n",
        "    \n",
        "  return X\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "66Y9OHfQbGA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_mean_for_features(X):\n",
        "  m = X.shape[0]\n",
        "  X_mean = np.zeros((m,1))\n",
        "  for i in range(m):\n",
        "    X_mean[i] = np.mean(X[i,:], axis=0)\n",
        "  return X_mean\n",
        "\n",
        "def scale_standard_for_samples(X, X_mean):\n",
        "  ss = StandardScaler()\n",
        "  ss.fit(X_mean)\n",
        "\n",
        "  X = ss.transform(X)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6OnpKlvHkRTW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_predictions(X, y, model, X_ini,out=False,):\n",
        "  preds = model.predict(X)\n",
        "  y_predict = np.where(preds > 0.5, 1, 0)\n",
        "  recall = recall_score(y, y_predict)\n",
        "  print('Recall = ', recall, 'Precision = ', precision_score(y, y_predict))\n",
        "  cm  = confusion_matrix(y, y_predict)\n",
        "  print(cm)\n",
        "  if out is True:\n",
        "    for i in range(X.shape[0]):\n",
        "      if abs(y_predict[i] - y[i])!= 0:\n",
        "        print(y[i], preds[i], X_ini[i], np.ndarray.tolist(X[i]))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p0FREjTx_NpO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import data sets"
      ]
    },
    {
      "metadata": {
        "id": "fdz_7GPb_NpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data_train = pd.read_csv('sources/train.csv')\n",
        "#data_test = pd.read_csv('sources/test_v7_v8.csv')\n",
        "\n",
        "data1_train = pd.read_csv('train_y1_v8.csv')\n",
        "data0_train = pd.read_csv('train_y0_v8.csv')\n",
        "\n",
        "X = np.vstack((data1_train.drop(['Y'], axis='columns').values, data0_train.drop(['Y'], axis='columns').values))\n",
        "\n",
        "y = np.hstack((data1_train['Y'].values, data0_train['Y'].values))\n",
        "X_ini = X.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oCSpZao5ePFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_add = pd.read_csv('train_0_change_1_to_close.csv')\n",
        "\n",
        "X_add = data_add.drop(['Y'], axis='columns').values\n",
        "y_add = data_add['Y'].values\n",
        "\n",
        "X = np.vstack((X, X_add))\n",
        "y = np.hstack((y, y_add))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VAqN3pkFFUsW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_v4 = pd.read_csv('train_0_v4.csv')\n",
        "\n",
        "X_add = data_add.drop(['Y'], axis='columns').values\n",
        "y_add = data_add['Y'].values\n",
        "\n",
        "X = np.vstack((X, X_add))\n",
        "y = np.hstack((y, y_add))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h0RDqrhyPqbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scale_X = scale_substraction_mean_for_1sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yWkLvtCGJL8",
        "colab_type": "code",
        "outputId": "75abc371-eaa8-439f-a0b6-9a237e721fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "X = scale_X(X)\n",
        "\n",
        "X_train,X_dev,y_train,y_dev = train_test_split(X, y, test_size=0.2, \\\n",
        "                                               shuffle=True, stratify=y)\n",
        "\n",
        "class_weights_train = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y), y)\n",
        "print(class_weights)\n",
        "print(class_weights[0]/(class_weights[1]+class_weights[0]))\n",
        "calculation_classes(y, y_dev)\n",
        "\n",
        "X = np.expand_dims(X, axis=2)\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_dev = np.expand_dims(X_dev, axis=2)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5518884  5.31803279]\n",
            "0.09401972872996302\n",
            "\t\tTRAIN DATA\tTEST DATA\n",
            "Negative\t 70536    90.6 % \t 14108    90.6 %\n",
            "Positive\t  7320   9.4 %\t 1464   9.4 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oPZjFAaNGvc_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_v4_test = pd.read_csv('test_v4_7615.csv')\n",
        "X_v4 = data_v4_test.drop(['Y'], axis='columns').values\n",
        "y_v4 = data_v4_test['Y'].values\n",
        "test_v4 =  data_v4_test.drop(['Y'], axis='columns').values\n",
        "\n",
        "X_v4 = scale_X(X_v4)\n",
        "X_v4 = np.expand_dims(X_v4, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lAtb7uNZKwLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_v7v8 = pd.read_csv('test_v7_v8.csv')\n",
        "\n",
        "X_v7v8 = data_v7v8.drop(['Y'], axis='columns').values\n",
        "test_v7v8 =  data_v7v8.drop(['Y'], axis='columns').values\n",
        "y_v7v8 = data_v7v8['Y'].values\n",
        "\n",
        "X_v7v8 = scale_X(X_v7v8)\n",
        "X_v7v8 = np.expand_dims(X_v7v8, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gK6YT84J_NpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data_test = pd.read_csv('sources/test_v3.csv')\n",
        "data_v3 = pd.read_csv('test_v3.csv')\n",
        "\n",
        "X_v3 = data_v3.drop(['Y'], axis='columns').values\n",
        "test_v3 =  data_v3.drop(['Y'], axis='columns').values\n",
        "y_v3 = data_v3['Y'].values\n",
        "\n",
        "X_v3 = scale_X(X_v3)\n",
        "X_v3 = np.expand_dims(X_v3, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LwZN3_Nm_Npj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NN on train/dev sets"
      ]
    },
    {
      "metadata": {
        "id": "FFJ0lUqb_NpM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Input, GRU, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "\n",
        "def model_GRU(input_shape, Ty, hidden_size):\n",
        "    i = Input(shape=input_shape, dtype='float32')\n",
        "    X = GRU(hidden_size, return_sequences=False)(i)\n",
        "    \n",
        "    X = Dense(Ty, activation='sigmoid')(X)\n",
        "    model = Model(inputs=[i], outputs=X)\n",
        "    \n",
        "    return model\n",
        "  \n",
        "def model_LSTM(hidden_size):  \n",
        "  model = Sequential()\n",
        "  model.add(LSTM(hidden_size, return_sequences=False, input_shape=(Tx,1)))\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UXEstYQtR2lI",
        "colab_type": "code",
        "outputId": "74dfdafb-ba6d-4aef-8668-646e09afd45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# For ready model\n",
        "'''GRU_model = model_GRU((Tx,1),Ty)#LSTM_model.summary()\n",
        "GRU_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "GRU_model.load_weights('GRU_sequence_weights.h5')'''"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"GRU_model = model_GRU((Tx,1),Ty)#LSTM_model.summary()\\nGRU_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n\\n\\nGRU_model.load_weights('GRU_sequence_weights.h5')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "metadata": {
        "id": "W6dszbna_Npk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Tx=  6\n",
        "Ty = 1\n",
        "epochs = 5\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jncFQcYy_Npn",
        "colab_type": "code",
        "outputId": "9afd9a19-6075-4a90-e578-fc017ec8ca72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "GRU_model = model_LSTM(16)\n",
        "opt = Adam(lr=0.02, beta_1=0.9, beta_2=0.999)\n",
        "GRU_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "logs = GRU_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=True,\\\n",
        "                    validation_data=(X_dev, y_dev), verbose=2, class_weight=class_weights_train, \\\n",
        "                    initial_epoch=0)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 62284 samples, validate on 15572 samples\n",
            "Epoch 1/5\n",
            " - 11s - loss: 0.1940 - acc: 0.9396 - val_loss: 0.0246 - val_acc: 0.9967\n",
            "Epoch 2/5\n",
            " - 8s - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0132 - val_acc: 0.9943\n",
            "Epoch 3/5\n",
            " - 8s - loss: 0.0148 - acc: 0.9959 - val_loss: 0.0100 - val_acc: 0.9970\n",
            "Epoch 4/5\n",
            " - 8s - loss: 0.0100 - acc: 0.9972 - val_loss: 0.0126 - val_acc: 0.9969\n",
            "Epoch 5/5\n",
            " - 8s - loss: 0.0102 - acc: 0.9971 - val_loss: 0.0112 - val_acc: 0.9958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NW-in0amJ5DR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.0005)\n",
        "GRU_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FUVkbjfKh0H",
        "colab_type": "code",
        "outputId": "db566c0f-d38b-4110-934e-5ec8cf299897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 1\n",
        "logs = GRU_model.fit(X_train, y_train , epochs=n_epochs, batch_size=batch_size, shuffle=True,\\\n",
        "                    validation_data=(X_dev, y_dev), verbose=2, class_weight=class_weights_train)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 62284 samples, validate on 15572 samples\n",
            "Epoch 1/1\n",
            " - 8s - loss: 5.2782e-04 - acc: 0.9999 - val_loss: 4.1907e-04 - val_acc: 0.9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qWip3visjS9M",
        "colab_type": "code",
        "outputId": "0a427bee-7ab6-4e3d-f222-8dc23c7f275d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "make_predictions(X,y, GRU_model,X_ini, out=False)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall =  1.0 Precision =  0.9993174061433447\n",
            "[[70531     5]\n",
            " [    0  7320]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HWZGW_EPepGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#make_predictions(X_dev,y_dev, out=True, model=GRU_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4s53hYsv2Jbo",
        "colab_type": "code",
        "outputId": "2fd63174-01cb-4c0f-f6af-e28bc1e5251c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "make_predictions(X_v7v8, y_v7v8, out=True, model=GRU_model, X_ini=test_v7v8)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall =  1.0 Precision =  1.0\n",
            "[[13  0]\n",
            " [ 0 46]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KAVqJ0Etc1B8",
        "colab_type": "code",
        "outputId": "e2c1a6e7-08bb-4acf-a919-4a1fd4e048be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "make_predictions(X_v3, y_v3, out=True, model=GRU_model, X_ini=test_v3)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall =  0.9811320754716981 Precision =  0.8524590163934426\n",
            "[[33  9]\n",
            " [ 1 52]]\n",
            "0.0 [0.64055765] [-0.377 -0.231 -0.2   -0.155  0.027  0.208] [[-0.25566666666666665], [-0.10966666666666668], [-0.07866666666666668], [-0.033666666666666664], [0.14833333333333334], [0.32933333333333337]]\n",
            "0.0 [0.88283145] [-0.377 -0.231 -0.2   -0.155  0.027  0.227] [[-0.2588333333333333], [-0.11283333333333333], [-0.08183333333333333], [-0.036833333333333315], [0.1451666666666667], [0.3451666666666667]]\n",
            "0.0 [0.92472976] [-0.377 -0.231 -0.2   -0.155  0.027  0.242] [[-0.2613333333333333], [-0.11533333333333333], [-0.08433333333333333], [-0.03933333333333332], [0.1426666666666667], [0.3576666666666667]]\n",
            "0.0 [0.9648842] [-0.377 -0.231 -0.2   -0.155  0.027  0.261] [[-0.2645], [-0.11850000000000001], [-0.08750000000000001], [-0.042499999999999996], [0.1395], [0.3735]]\n",
            "0.0 [0.9904851] [-0.377 -0.231 -0.2   -0.155  0.027  0.279] [[-0.2675], [-0.12150000000000001], [-0.09050000000000001], [-0.0455], [0.1365], [0.38849999999999996]]\n",
            "0.0 [0.9999474] [-0.377 -0.231 -0.2   -0.155  0.027  0.317] [[-0.2738333333333333], [-0.12783333333333335], [-0.09683333333333334], [-0.05183333333333333], [0.13016666666666668], [0.4201666666666667]]\n",
            "0.0 [0.9999943] [-0.377 -0.231 -0.2   -0.155  0.027  0.333] [[-0.27649999999999997], [-0.1305], [-0.09949999999999999], [-0.05449999999999998], [0.12750000000000003], [0.4335]]\n",
            "0.0 [0.9999999] [-0.377 -0.231 -0.2   -0.155  0.027  0.378] [[-0.284], [-0.138], [-0.107], [-0.061999999999999986], [0.12000000000000002], [0.471]]\n",
            "0.0 [0.9999999] [-0.377 -0.231 -0.2   -0.155  0.027  0.402] [[-0.288], [-0.14200000000000002], [-0.111], [-0.06599999999999999], [0.11600000000000002], [0.49100000000000005]]\n",
            "1.0 [0.31623995] [-0.417 -0.365 -0.31  -0.262 -0.194 -0.126] [[-0.13800000000000007], [-0.08600000000000002], [-0.031000000000000028], [0.01699999999999996], [0.08499999999999999], [0.15299999999999997]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m23acahMtsOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1159
        },
        "outputId": "38e044bd-92ad-44e2-d2a2-823d2f4f72f9"
      },
      "cell_type": "code",
      "source": [
        "make_predictions(X_v4, y_v4, out=True, model=GRU_model, X_ini=test_v4)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall =  0.0 Precision =  0.0\n",
            "[[10 61]\n",
            " [ 0  0]]\n",
            "0.0 [1.] [-0.493 -0.476 -0.335 -0.11   0.023  0.169] [[-0.28933333333333333], [-0.2723333333333333], [-0.13133333333333333], [0.09366666666666669], [0.22666666666666668], [0.3726666666666667]]\n",
            "0.0 [0.9999999] [-0.493 -0.476 -0.335 -0.11   0.059  0.169] [[-0.29533333333333334], [-0.2783333333333333], [-0.13733333333333334], [0.08766666666666668], [0.2566666666666667], [0.3666666666666667]]\n",
            "0.0 [0.9999998] [-0.493 -0.447 -0.335 -0.11   0.059  0.169] [[-0.3001666666666667], [-0.25416666666666665], [-0.1421666666666667], [0.08283333333333333], [0.25183333333333335], [0.36183333333333334]]\n",
            "0.0 [0.9999997] [-0.493 -0.447 -0.335 -0.11   0.139  0.169] [[-0.3135], [-0.2675], [-0.15550000000000003], [0.06949999999999999], [0.3185], [0.3485]]\n",
            "0.0 [1.] [-0.493 -0.447 -0.302 -0.11   0.023  0.169] [[-0.29966666666666664], [-0.25366666666666665], [-0.10866666666666663], [0.08333333333333336], [0.21633333333333335], [0.36233333333333334]]\n",
            "0.0 [1.] [-0.493 -0.447 -0.302 -0.11   0.059  0.169] [[-0.30566666666666664], [-0.25966666666666666], [-0.11466666666666664], [0.07733333333333335], [0.24633333333333335], [0.35633333333333334]]\n",
            "0.0 [1.] [-0.493 -0.334 -0.226 -0.11   0.023  0.169] [[-0.3311666666666666], [-0.1721666666666666], [-0.06416666666666665], [0.051833333333333356], [0.18483333333333335], [0.3308333333333333]]\n",
            "0.0 [1.] [-0.493 -0.334 -0.226 -0.11   0.059  0.169] [[-0.3371666666666666], [-0.1781666666666666], [-0.07016666666666665], [0.04583333333333335], [0.21483333333333335], [0.3248333333333333]]\n",
            "0.0 [1.] [-0.493 -0.334 -0.174 -0.11   0.023  0.169] [[-0.3398333333333333], [-0.1808333333333333], [-0.020833333333333315], [0.04316666666666667], [0.17616666666666667], [0.32216666666666666]]\n",
            "0.0 [1.] [-0.493 -0.334 -0.174 -0.11   0.059  0.169] [[-0.3458333333333333], [-0.1868333333333333], [-0.02683333333333332], [0.03716666666666667], [0.20616666666666666], [0.31616666666666665]]\n",
            "0.0 [0.82158065] [-0.493 -0.334 -0.155  0.05   0.139  0.169] [[-0.389], [-0.22999999999999998], [-0.05100000000000002], [0.15399999999999997], [0.243], [0.27299999999999996]]\n",
            "0.0 [0.99999976] [-0.493 -0.299 -0.226 -0.11   0.023  0.169] [[-0.33699999999999997], [-0.14299999999999996], [-0.06999999999999998], [0.04600000000000003], [0.17900000000000002], [0.325]]\n",
            "0.0 [0.94723535] [-0.493 -0.299 -0.226 -0.11   0.059  0.169] [[-0.34299999999999997], [-0.14899999999999997], [-0.07599999999999998], [0.04000000000000002], [0.20900000000000002], [0.319]]\n",
            "0.0 [1.] [-0.493 -0.299 -0.174 -0.11   0.023  0.169] [[-0.3456666666666667], [-0.15166666666666664], [-0.026666666666666644], [0.03733333333333334], [0.17033333333333334], [0.31633333333333336]]\n",
            "0.0 [0.9999999] [-0.483 -0.476 -0.335 -0.11   0.023  0.169] [[-0.2809999999999999], [-0.274], [-0.13299999999999998], [0.09200000000000004], [0.22500000000000003], [0.371]]\n",
            "0.0 [0.9999999] [-0.483 -0.476 -0.335 -0.11   0.059  0.169] [[-0.2869999999999999], [-0.28], [-0.13899999999999998], [0.08600000000000003], [0.25500000000000006], [0.365]]\n",
            "0.0 [0.9999999] [-0.483 -0.447 -0.335 -0.11   0.059  0.169] [[-0.2918333333333333], [-0.25583333333333336], [-0.14383333333333334], [0.08116666666666668], [0.2501666666666667], [0.36016666666666663]]\n",
            "0.0 [0.99999964] [-0.483 -0.447 -0.335 -0.11   0.139  0.169] [[-0.3051666666666667], [-0.26916666666666667], [-0.1571666666666667], [0.06783333333333331], [0.3168333333333333], [0.3468333333333333]]\n",
            "0.0 [1.] [-0.483 -0.447 -0.302 -0.11   0.023  0.169] [[-0.29133333333333333], [-0.2553333333333333], [-0.11033333333333331], [0.08166666666666668], [0.21466666666666667], [0.3606666666666667]]\n",
            "0.0 [1.] [-0.483 -0.447 -0.302 -0.11   0.059  0.169] [[-0.29733333333333334], [-0.2613333333333333], [-0.11633333333333332], [0.07566666666666667], [0.24466666666666667], [0.3546666666666667]]\n",
            "0.0 [1.] [-0.483 -0.334 -0.226 -0.11   0.023  0.169] [[-0.3228333333333333], [-0.17383333333333328], [-0.06583333333333333], [0.05016666666666668], [0.18316666666666667], [0.32916666666666666]]\n",
            "0.0 [1.] [-0.483 -0.334 -0.226 -0.11   0.059  0.169] [[-0.3288333333333333], [-0.1798333333333333], [-0.07183333333333333], [0.044166666666666674], [0.21316666666666667], [0.32316666666666666]]\n",
            "0.0 [1.] [-0.483 -0.334 -0.174 -0.11   0.023  0.169] [[-0.3315], [-0.18249999999999997], [-0.022499999999999992], [0.041499999999999995], [0.1745], [0.3205]]\n",
            "0.0 [1.] [-0.483 -0.334 -0.174 -0.11   0.059  0.169] [[-0.3375], [-0.18849999999999997], [-0.028499999999999998], [0.03549999999999999], [0.2045], [0.3145]]\n",
            "0.0 [0.91776973] [-0.483 -0.334 -0.155  0.05   0.139  0.169] [[-0.38066666666666665], [-0.23166666666666663], [-0.05266666666666668], [0.15233333333333332], [0.24133333333333334], [0.2713333333333333]]\n",
            "0.0 [0.9999994] [-0.483 -0.299 -0.226 -0.11   0.023  0.169] [[-0.32866666666666666], [-0.14466666666666664], [-0.07166666666666666], [0.04433333333333335], [0.17733333333333334], [0.32333333333333336]]\n",
            "0.0 [0.80617344] [-0.483 -0.299 -0.226 -0.11   0.059  0.169] [[-0.33466666666666667], [-0.15066666666666664], [-0.07766666666666666], [0.038333333333333344], [0.20733333333333334], [0.31733333333333336]]\n",
            "0.0 [1.] [-0.483 -0.299 -0.174 -0.11   0.023  0.169] [[-0.33733333333333326], [-0.1533333333333333], [-0.028333333333333294], [0.035666666666666694], [0.1686666666666667], [0.31466666666666665]]\n",
            "0.0 [0.99999994] [-0.483 -0.299 -0.174 -0.11   0.059  0.169] [[-0.34333333333333327], [-0.1593333333333333], [-0.0343333333333333], [0.02966666666666669], [0.19866666666666669], [0.30866666666666664]]\n",
            "0.0 [0.9999998] [-0.44  -0.476 -0.335 -0.11   0.059  0.169] [[-0.25116666666666665], [-0.2871666666666667], [-0.14616666666666664], [0.07883333333333338], [0.24783333333333338], [0.35783333333333334]]\n",
            "0.0 [0.9999999] [-0.44  -0.447 -0.335 -0.11   0.023  0.169] [[-0.24999999999999997], [-0.257], [-0.145], [0.08000000000000003], [0.21300000000000002], [0.359]]\n",
            "0.0 [0.99999976] [-0.44  -0.447 -0.335 -0.11   0.059  0.169] [[-0.256], [-0.263], [-0.151], [0.07400000000000002], [0.24300000000000002], [0.353]]\n",
            "0.0 [0.9999996] [-0.44  -0.447 -0.335 -0.11   0.139  0.169] [[-0.2693333333333333], [-0.2763333333333333], [-0.16433333333333336], [0.06066666666666666], [0.30966666666666665], [0.3396666666666667]]\n",
            "0.0 [1.] [-0.44  -0.447 -0.302 -0.11   0.023  0.169] [[-0.25549999999999995], [-0.26249999999999996], [-0.11749999999999997], [0.07450000000000002], [0.20750000000000002], [0.35350000000000004]]\n",
            "0.0 [0.9999999] [-0.44  -0.447 -0.302 -0.11   0.059  0.169] [[-0.26149999999999995], [-0.26849999999999996], [-0.12349999999999997], [0.06850000000000002], [0.23750000000000002], [0.34750000000000003]]\n",
            "0.0 [1.] [-0.44  -0.334 -0.226 -0.11   0.023  0.169] [[-0.287], [-0.18099999999999994], [-0.07299999999999998], [0.043000000000000024], [0.17600000000000002], [0.322]]\n",
            "0.0 [0.9999733] [-0.44  -0.334 -0.226 -0.11   0.059  0.169] [[-0.293], [-0.18699999999999994], [-0.07899999999999999], [0.03700000000000002], [0.20600000000000002], [0.316]]\n",
            "0.0 [0.99960756] [-0.44  -0.299 -0.226 -0.11   0.023  0.169] [[-0.29283333333333333], [-0.15183333333333332], [-0.07883333333333334], [0.03716666666666667], [0.17016666666666666], [0.31616666666666665]]\n",
            "0.0 [1.] [-0.44  -0.299 -0.174 -0.11   0.023  0.169] [[-0.3015], [-0.16049999999999995], [-0.03549999999999995], [0.02850000000000004], [0.16150000000000003], [0.3075]]\n",
            "0.0 [0.9999986] [-0.44  -0.299 -0.174 -0.11   0.059  0.169] [[-0.3075], [-0.16649999999999995], [-0.041499999999999954], [0.022500000000000034], [0.19150000000000003], [0.3015]]\n",
            "0.0 [1.] [-0.44  -0.299 -0.155 -0.11   0.023  0.169] [[-0.30466666666666664], [-0.16366666666666665], [-0.019666666666666666], [0.025333333333333333], [0.15833333333333333], [0.30433333333333334]]\n",
            "0.0 [0.99999976] [-0.4   -0.476 -0.335 -0.11   0.059  0.169] [[-0.21783333333333332], [-0.29383333333333334], [-0.15283333333333332], [0.0721666666666667], [0.2411666666666667], [0.3511666666666667]]\n",
            "0.0 [0.9999998] [-0.4   -0.447 -0.335 -0.11   0.059  0.169] [[-0.22266666666666668], [-0.26966666666666667], [-0.15766666666666668], [0.06733333333333334], [0.23633333333333334], [0.3463333333333333]]\n",
            "0.0 [0.9999997] [-0.4   -0.447 -0.335 -0.11   0.139  0.169] [[-0.23600000000000002], [-0.28300000000000003], [-0.171], [0.054000000000000006], [0.30300000000000005], [0.33299999999999996]]\n",
            "0.0 [0.9999988] [-0.4   -0.334 -0.226 -0.11   0.023  0.169] [[-0.2536666666666667], [-0.18766666666666662], [-0.07966666666666666], [0.03633333333333334], [0.16933333333333334], [0.31533333333333335]]\n",
            "0.0 [0.97697073] [-0.4   -0.299 -0.226 -0.11   0.023  0.169] [[-0.25949999999999995], [-0.15849999999999995], [-0.08549999999999996], [0.03050000000000004], [0.16350000000000003], [0.3095]]\n",
            "0.0 [0.9999999] [-0.4   -0.299 -0.174 -0.11   0.023  0.169] [[-0.26816666666666666], [-0.16716666666666666], [-0.04216666666666666], [0.02183333333333333], [0.15483333333333332], [0.3008333333333333]]\n",
            "0.0 [0.99999905] [-0.4   -0.205 -0.096  0.05   0.139  0.169] [[-0.3428333333333334], [-0.14783333333333334], [-0.03883333333333335], [0.10716666666666666], [0.19616666666666666], [0.22616666666666663]]\n",
            "0.0 [0.9999989] [-0.4   -0.2   -0.096  0.05   0.139  0.169] [[-0.3436666666666667], [-0.14366666666666666], [-0.03966666666666666], [0.10633333333333334], [0.19533333333333336], [0.22533333333333333]]\n",
            "0.0 [0.9999998] [-0.38  -0.476 -0.335 -0.11   0.059  0.169] [[-0.20116666666666663], [-0.2971666666666667], [-0.15616666666666665], [0.06883333333333337], [0.23783333333333337], [0.3478333333333333]]\n",
            "0.0 [0.9999998] [-0.38  -0.447 -0.335 -0.11   0.059  0.169] [[-0.206], [-0.273], [-0.161], [0.06400000000000002], [0.233], [0.34299999999999997]]\n",
            "0.0 [0.9999997] [-0.38  -0.447 -0.335 -0.11   0.139  0.169] [[-0.21933333333333335], [-0.28633333333333333], [-0.17433333333333337], [0.05066666666666665], [0.29966666666666664], [0.32966666666666666]]\n",
            "0.0 [0.99952614] [-0.38  -0.334 -0.226 -0.11   0.023  0.169] [[-0.237], [-0.19099999999999995], [-0.08299999999999999], [0.033000000000000015], [0.166], [0.312]]\n",
            "0.0 [0.9807725] [-0.38  -0.299 -0.226 -0.11   0.023  0.169] [[-0.24283333333333332], [-0.1618333333333333], [-0.08883333333333332], [0.027166666666666686], [0.16016666666666668], [0.3061666666666667]]\n",
            "0.0 [0.9999996] [-0.38  -0.205 -0.096  0.05   0.139  0.169] [[-0.3261666666666667], [-0.15116666666666667], [-0.042166666666666686], [0.10383333333333332], [0.19283333333333333], [0.2228333333333333]]\n",
            "0.0 [0.9999995] [-0.38  -0.2   -0.096  0.05   0.139  0.169] [[-0.327], [-0.14700000000000002], [-0.043000000000000003], [0.10300000000000001], [0.192], [0.22199999999999998]]\n",
            "0.0 [0.99999946] [-0.38  -0.194 -0.096  0.05   0.139  0.169] [[-0.328], [-0.142], [-0.04400000000000002], [0.10199999999999998], [0.191], [0.22099999999999997]]\n",
            "0.0 [1.] [-0.308 -0.205 -0.096  0.05   0.139  0.169] [[-0.26616666666666666], [-0.16316666666666665], [-0.054166666666666675], [0.09183333333333332], [0.18083333333333335], [0.21083333333333332]]\n",
            "0.0 [1.] [-0.308 -0.2   -0.096  0.05   0.139  0.169] [[-0.267], [-0.15900000000000003], [-0.055000000000000014], [0.091], [0.18], [0.20999999999999996]]\n",
            "0.0 [0.9999999] [-0.308 -0.194 -0.096  0.05   0.139  0.169] [[-0.268], [-0.154], [-0.056000000000000015], [0.09], [0.179], [0.20899999999999996]]\n",
            "0.0 [0.9999999] [ 0.284  0.274  0.192  0.09   0.023 -0.065] [[0.15099999999999997], [0.14099999999999996], [0.059], [-0.04300000000000001], [-0.11000000000000001], [-0.198]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "A0pyJZ9beuDl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#make_predictions(X_add, y_add, out=True, model=GRU_model, X_ini=X_ini_add)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZSplb-P_Npv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot_loss(epochs, logplot_loss(epos.history.get('loss'), logs.history.get('val_loss'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SPeSwZ7d_Npy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#acc_graph(epochs, logs.history.get('acc'), logs.history.get('val_acc'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CmrNU65L_NqA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GRU_model.save_weights('LSTM_sequence_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g392u_wAK9zd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('LSTM_sequence_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MmNRobJa_NqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LSTM_model = model((Tx,1),Ty)\n",
        "#LSTM_model.summary()\n",
        "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "logs = LSTM_model.fit(X_train, y_train , epochs=epochs, batch_size=batch_size, shuffle=True,\\\n",
        "               validation_data=(X_dev, y_dev), verbose=0, class_weight=class_weights_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qh-CPRLQ_NqG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Final fit NN on all train set"
      ]
    },
    {
      "metadata": {
        "id": "isNoPp6K_NqH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Tx=  6\n",
        "Ty = 1\n",
        "epochs = 250\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ks1Usr1x_NqK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LSTM_model = model((Tx,1),Ty)\n",
        "#LSTM_model.summary()\n",
        "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "LSTM_model.fit(X, y , epochs=epochs, batch_size=batch_size, shuffle=True,\\\n",
        "               verbose=0, class_weight=class_weights)\n",
        "LSTM_model.save_weights('sources/LSTM_sequence_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_R7AAT5T_NqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(LSTM_model.summary())\n",
        "test_preds = LSTM_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crGaA4yU_NqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(X_test.shape[0]):\n",
        "    if test_preds[i] > 0.5:\n",
        "        print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9-v1zer_NqR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LSTM_model = model((Tx,1),Ty)\n",
        "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "LSTM_model.load_weights('LSTM_sequence_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zIhaqheq_NqT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_preds = LSTM_model.predict(X_test)\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    if test_preds[i] > 0.5:\n",
        "        print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDXYk528_NqY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}